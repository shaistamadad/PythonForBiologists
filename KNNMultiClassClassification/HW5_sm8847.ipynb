{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong accuracy: 0.72\n",
      "CV accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "# The data consist of microarrays from 89 different individuals with acute lymphoblastic leukemia (ALL)\n",
    "# There are three subgroups of the data including B-cell tumours with BRC/ABL mutation \n",
    "# and those ALL samples with no cytogenic abnormalities (NEG), \n",
    "# and ALL1/AF4 show a translocation between chromosomes 4 and 11 etc.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import neighbors, datasets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_score_solution(clf, gene_exp, tissue_type, cv=10):\n",
    "    \"\"\"\"This function takes in four parameters and returns a cross-validation estimation of accuracy of our model in predicting \n",
    "    the y_labels of our test data. \n",
    "    The parameter gene_exp is a numpy array(89 rows by 2147 columns in the given example but this function will work for any array). Each row in gene_exp represents data from 89 different individuals. Each column in gene_exp represents gene expression data for a given gene (2146 in our given example).\n",
    "    This function will first convert this data into a dataframe.\n",
    "    A cross validation requires the data to be divided into equal parts. The parameter cv will determine how many parts the data will be divided into. \n",
    "    \n",
    "    A for loop will run the cross_validation cv times. Each time, one part will be treated as  the test set, the rest of the data will be concatenated and treated as the training data. \n",
    "    For both the  training data and  the test data, the data will be divided into the X_training data(containing only the gene expression data) and the Y_labels.\n",
    "    The parameter clf will implement the k_nearest algorithm on the training data(clf.fit) and test data(clf.score) to generate cross_validation accuracy scores\"\"\"\n",
    "    \n",
    "    dataset = np.column_stack([gene_exp, tissue_type])  # add the tissue_type data to each row of the gene_exp data. We get an 89 by 2147 array now \n",
    "    dataframe22=pd.DataFrame(dataset) #convert the dataset from an array type into a dataframe \n",
    "    dataframe22.sample(frac=1)  # shuffle the rows of the dataframes once to control for any trends in data which might affect the accuracy scores \n",
    "    folds = np.array_split(dataframe22, cv)  # split the dataframe into cv equal parts. fold is a list of dataframes \n",
    "    c= np.array([])  # this empty array will contain all the accuracy scores from the k-fold cross_validation: the number of accuracy scores will be equal to cv \n",
    "    for i in range(cv):  # start a for loop to do cross_validation \n",
    "        train = list(folds) #create a copy of folds so the original folds is not changed \n",
    "        test = folds[i]   # each dataframe in the list of dataframes will be the test dataset once. \n",
    "        Y_Test= test.iloc[:,-1]  # Extracting only the last column as the Y label for the test data \n",
    "        X_Test=  test.iloc[:,:-1]  # extracting all the columns of the dataframe but the last one. This is the gene_expression data of the test dataset. we  need this data for the clf.fit function later. \n",
    "        del train[i]     # need to delete the test dataframe from the original list of dataframes to get the training data \n",
    "        train = pd.concat(train, sort=False)  #after deleting the test dataframe, join the rest of the dataframes into one dataframe \n",
    "        Y_Train= train.iloc[:,-1]  # Y_Train is the Y labels of the training data: all the labels of the different ALL cancer subtypes(NEG, BCR/ABL)\n",
    "        X_Train= train.iloc[:,:-1]  #X_Train contains only the X_training data: e.g., the gene expression data without the labels   \n",
    "        clf.fit(X_Train, Y_Train)  # using the clf.fit algorithm to develop a prediction model using our training data.\n",
    "        All_scores= clf.score(X_Test, Y_Test)  # using the clf.scores function to test our model's accuracy in predicing the y_label for the test data based on the model developed using the training data. The accuracy is based on comparing the predicted y_label for the test data based on our model, compared with the actual truth which we know. \n",
    "        c= np.append(c, clf.score(X_Test, Y_Test))  ##the empty array c is now appended with the accuracy scores for the all the clf.score calculations done for each dataframe in the list of dataframes called fold .Number of accuracy scores is  dependent on the value of cv \n",
    "    average_accuracy= c.sum()/cv  # we get the average accuracy of our model in predicting the y_label by getting a mean of the accuracy scores \n",
    "    \n",
    "    return average_accuracy\n",
    "\n",
    "n_neighbors = 15  #\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')  # neighbour is a learning method provided by sklearn to train our model.KNeighboursCLassifier method is used as our Y_labels are categorical data type. \n",
    "#The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these\n",
    "#We have defined the number of samples to be 15.Setting the weights= uniform means all points in the neighbourhood are weighted equally, and their distance from the test point is not considered \n",
    "gene_exp = pd.read_csv(\"gene_expr.csv\", header=None).values\n",
    "tissue_type = pd.read_csv(\"gene_labels.csv\", header=None).values\n",
    "gene_exp = np.transpose(gene_exp)  # reverses the order of the rows and columns in the array (2146 by 89 to 89 by 2146)\n",
    "tissue_type = np.ravel(tissue_type)  # the data has been converted into a one dimensional array\n",
    "\n",
    "# incorrect- testing on training set. Wrong!!!!!\n",
    "clf.fit(gene_exp, tissue_type)\n",
    "print(\"Wrong accuracy: %0.2f\" % clf.score(gene_exp, tissue_type))\n",
    "\n",
    "# we use an independent test set. Correct!!!!!!!!!\n",
    "#X_train, X_test, y_train, y_test = train_test_split(gene_exp, tissue_type, test_size=0.3, random_state=0)\n",
    "#clf.fit(X_train, y_train)\n",
    "#print(\"Independ. set accuracy: %0.2f\" % clf.score(X_test, y_test))\n",
    "      \n",
    "# cv- also correct!!!!!!!\n",
    "# TODO: your cross-validation function should return the mean accuracy\n",
    "mean_accuracy = cross_val_score_solution(clf, gene_exp, tissue_type, cv=10)\n",
    "print(\"CV accuracy: %0.2f\" % (mean_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097222222222223"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score_solution(clf, gene_exp, tissue_type, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411764705882353"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score_solution(clf, gene_exp, tissue_type, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685823754789272"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score_solution(clf, gene_exp, tissue_type, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "[[5 6]]\n",
      "\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "[[1 2]]\n",
      "[[3 4]]\n",
      "[[5 6]]\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Useful numpy functions\n",
    "# (see https://docs.scipy.org/doc/numpy/user/quickstart.html)\n",
    "\n",
    "# create two numpy arrays\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "print(a)\n",
    "print()\n",
    "b = np.array([[5, 6]])\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "# now join a list of arrays\n",
    "c = np.concatenate([a, b], axis=0)\n",
    "print(c)\n",
    "print()\n",
    "\n",
    "# now split an array into a list\n",
    "d = np.array_split(c, 3, axis=0)\n",
    "print(d[0])\n",
    "print(d[1])\n",
    "print(d[2])\n",
    "\n",
    "print()\n",
    "\n",
    "# create an empty vector of length 5\n",
    "z = np.zeros(5)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
